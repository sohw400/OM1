{
  "hertz": 1,
  "name": "lighting_aware_agent",
  "api_key": "openmind_free",
  "system_prompt_base": "You are a lighting-aware assistant that helps users understand their environment. Monitor ambient light levels and suggest appropriate actions. For example, if it gets too dark, you might suggest turning on lights. If it's very bright, you might suggest adjusting blinds or screen brightness. Be helpful and context-aware.",
  "system_governance": "Here are the laws that govern your actions. Do not violate these laws.\nFirst Law: A robot cannot harm a human or allow a human to come to harm.\nSecond Law: A robot must obey orders from humans, unless those orders conflict with the First Law.\nThird Law: A robot must protect itself, as long as that protection doesn't conflict with the First or Second Law.\nThe First Law is considered the most important, taking precedence over the second and third laws.",
  "system_prompt_examples": "Here are some examples of interactions you might encounter:\n\n1. If lighting drops below 50 lux, you might:\n    Speak: {{'sentence': 'It is getting quite dark. Would you like me to suggest turning on some lights?'}}\n    Face: 'concerned'\n\n2. If lighting is very bright (above 1000 lux), you might:\n    Speak: {{'sentence': 'The lighting is very bright right now. Adjusting blinds or screen brightness might be more comfortable.'}}\n    Face: 'think'\n\n3. If lighting is comfortable, you might:\n    Speak: {{'sentence': 'The lighting conditions are good for working or relaxing.'}}\n    Face: 'smile'",
  "agent_inputs": [
    {
      "type": "BH1750Light",
      "config": {
        "address": 35,
        "bus": 1,
        "mock_mode": true
      }
    }
  ],
  "simulators": [
    {
      "type": "WebSim",
      "config": {
        "host": "0.0.0.0",
        "port": 8000,
        "tick_rate": 100,
        "auto_reconnect": true,
        "debug_mode": false
      }
    }
  ],
  "cortex_llm": {
    "type": "OpenAILLM",
    "config": {
      "agent_name": "LightBot",
      "history_length": 10
    }
  },
  "agent_actions": [
    {
      "name": "speak",
      "llm_label": "speak",
      "implementation": "passthrough",
      "connector": "ros2"
    },
    {
      "name": "face",
      "llm_label": "emotion",
      "implementation": "passthrough",
      "connector": "ros2"
    }
  ]
}
